{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## BigDL Wide & Deep Recommender Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wide and Deep Learning Model, proposed by Google in 2016, is a DNN-Linear mixed model. Wide and deep learning has been used for Google App Store for their app recommendation.\n",
    "\n",
    "In this tutorial, we'll introduce how to use BigDL to train a wide linear model and a deep neural network, which is called Wide & Deep model. Wide & Deep model combines the strength of memorization and generalization. It's useful for generic large-scale regression and classification problems with sparse input features(e.g., categorical features with a large number of possible feature values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:25:57.976644Z",
     "start_time": "2018-04-03T10:25:54.475065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /Users/lizhichao/bin/spark-1.6.3-bin-hadoop2.6\n",
      "Adding /Users/lizhichao/anaconda/envs/bigdl04py27/lib/python2.7/site-packages/bigdl/share/lib/bigdl-0.5.0-SNAPSHOT-jar-with-dependencies.jar to BIGDL_JARS\n",
      "Prepending /Users/lizhichao/anaconda/envs/bigdl04py27/lib/python2.7/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\n",
      "Adding /Users/lizhichao/anaconda/envs/bigdl04py27/lib/python2.7/site-packages/bigdl/share/lib/bigdl-0.5.0-SNAPSHOT-jar-with-dependencies.jar to SPARK_CLASSPATH\n"
     ]
    }
   ],
   "source": [
    "#%pylab inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import datetime as dt\n",
    "\n",
    "from bigdl.dataset.transformer import *\n",
    "from bigdl.dataset.base import *\n",
    "from bigdl.nn.layer import *\n",
    "from bigdl.nn.criterion import *\n",
    "from bigdl.optim.optimizer import *\n",
    "from bigdl.util.common import *\n",
    "from utils import *\n",
    "\n",
    "init_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data\n",
    "Download training and testing data set from [Census Income Dataset](https://archive.ics.uci.edu/ml/datasets/Census+Income).\n",
    "Read and parse the dataset into Spark RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:26:00.932206Z",
     "start_time": "2018-04-03T10:26:00.506603Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bigdl.dataset.base import maybe_download\n",
    "from bigdl.util.common import get_spark_context\n",
    "sc = get_spark_context()\n",
    "train_file_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "test_file_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
    "\n",
    "absolutepath='file://' + os.getcwd() + '/'\n",
    "train_file_name = maybe_download('adult.data', 'census_dataset', train_file_url)\n",
    "test_file_name = maybe_download('adult.test', 'census_dataset', test_file_url)\n",
    "\n",
    "train_records = read(absolutepath + train_file_name, sc)\n",
    "test_records = read(absolutepath + test_file_name, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data set has 14 features age, workclass, fnlwgt, etc... and one label income_bracket. There is ten record of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:26:04.750862Z",
     "start_time": "2018-04-03T10:26:03.606396Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>160187</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>209642</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>45781</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>14084</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>159449</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age         workclass  fnlwgt  education education_num  \\\n",
       "0  39         State-gov   77516  Bachelors            13   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors            13   \n",
       "2  38           Private  215646    HS-grad             9   \n",
       "3  53           Private  234721       11th             7   \n",
       "4  28           Private  338409  Bachelors            13   \n",
       "5  37           Private  284582    Masters            14   \n",
       "6  49           Private  160187        9th             5   \n",
       "7  52  Self-emp-not-inc  209642    HS-grad             9   \n",
       "8  31           Private   45781    Masters            14   \n",
       "9  42           Private  159449  Bachelors            13   \n",
       "\n",
       "          marital_status         occupation   relationship   race  gender  \\\n",
       "0          Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1     Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2               Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3     Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4     Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "5     Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
       "6  Married-spouse-absent      Other-service  Not-in-family  Black  Female   \n",
       "7     Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "8          Never-married     Prof-specialty  Not-in-family  White  Female   \n",
       "9     Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "\n",
       "  capital_gain capital_loss hours_per_week native_country income_bracket  \n",
       "0         2174            0             40  United-States          <=50K  \n",
       "1            0            0             13  United-States          <=50K  \n",
       "2            0            0             40  United-States          <=50K  \n",
       "3            0            0             40  United-States          <=50K  \n",
       "4            0            0             40           Cuba          <=50K  \n",
       "5            0            0             40  United-States          <=50K  \n",
       "6            0            0             16        Jamaica          <=50K  \n",
       "7            0            0             45  United-States           >50K  \n",
       "8        14084            0             50  United-States           >50K  \n",
       "9         5178            0             40  United-States           >50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_records.take(10), columns=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:26:09.410290Z",
     "start_time": "2018-04-03T10:26:09.369557Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "           \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "           \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n",
    "           \"income_bracket\"]\n",
    "\n",
    "NUM_COLUMNS=15\n",
    "\n",
    "LABEL_COLUMN = \"label\"\n",
    "\n",
    "AGE, WORKCLASS, FNLWGT, EDUCATION, EDUCATION_NUM, MARITAL_STATUS, OCCUPATION, \\\n",
    "RELATIONSHIP, RACE, GENDER, CAPITAL_GAIN, CAPITAL_LOSS, HOURS_PER_WEEK, NATIVE_COUNTRY, \\\n",
    "LABEL = range(NUM_COLUMNS)\n",
    "\n",
    "EDUCATION_VOCAB = [\"Bachelors\", \"HS-grad\", \"11th\", \"Masters\", \"9th\",\n",
    "  \"Some-college\", \"Assoc-acdm\", \"Assoc-voc\", \"7th-8th\",\n",
    "  \"Doctorate\", \"Prof-school\", \"5th-6th\", \"10th\", \"1st-4th\",\n",
    "  \"Preschool\", \"12th\"] # 16\n",
    "MARITAL_STATUS_VOCAB = [\"Married-civ-spouse\", \"Divorced\", \"Married-spouse-absent\",\n",
    "    \"Never-married\", \"Separated\", \"Married-AF-spouse\", \"Widowed\"]\n",
    "RELATIONSHIP_VOCAB = [\"Husband\", \"Not-in-family\", \"Wife\", \"Own-child\", \"Unmarried\",\n",
    "    \"Other-relative\"]  # 6\n",
    "WORKCLASS_VOCAB = [\"Self-emp-not-inc\", \"Private\", \"State-gov\", \"Federal-gov\",\n",
    "    \"Local-gov\", \"?\", \"Self-emp-inc\", \"Without-pay\", \"Never-worked\"] # 9\n",
    "GENDER_VOCAB = [\"Female\", \"Male\"]\n",
    "AGE_BOUNDARIES = [18, 25, 30, 35, 40, 45, 50, 55, 60, 65]\n",
    "\n",
    "def hashbucket(sth, bucketsize = 1000):\n",
    "    return (id(sth) % bucketsize + bucketsize) % bucketsize\n",
    "\n",
    "def categorical_from_vocab_list(sth, vocab_list, default = -1):\n",
    "    if sth in vocab_list:\n",
    "        return vocab_list.index(sth)\n",
    "    else:\n",
    "        return default\n",
    "    \n",
    "def get_boundaries(numage, boundaries, default = -1):\n",
    "    if numage == '?':\n",
    "        return default\n",
    "    else:\n",
    "        for i in range(len(boundaries)):\n",
    "            if numage < boundaries[i]:\n",
    "                return i\n",
    "        return len(boundaries)\n",
    "    \n",
    "def get_label(label):\n",
    "    if label == \">50K\" or label == \">50K.\":\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def read(file, sc):\n",
    "    lines=sc.textFile(file).map(lambda line: list(map(lambda word: word.strip(), line.split(',')))).filter(lambda line: len(line) == NUM_COLUMNS)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform data to BigDL' Sample\n",
    "BigDL's Sample is a data structure who represents the features and label of data. So each record will be transform to a BigDL Sample, and BigDL will train the Wide&Deep with these Samples. \n",
    "\n",
    "The input BigDL Wide&Deep model required,  are two input tensors, one is SparseTensor for the Wide model, another is a DenseTensor for the Deep model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:26:22.213815Z",
     "start_time": "2018-04-03T10:26:12.140892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train records: 32561\n",
      "Total test records: 16281\n",
      "JTensor: storage: [0. 1. 0. ... 0. 0. 0.], shape: [5041], float\n"
     ]
    }
   ],
   "source": [
    "def to_sample(row):\n",
    "    #wide_column_shape = np.array([5006])\n",
    "    from keras.utils import np_utils\n",
    "    \n",
    "    wide_columns_dense = np.zeros(5006)\n",
    "    gender = categorical_from_vocab_list(row[GENDER], GENDER_VOCAB)\n",
    "    gender_oh = np_utils.to_categorical(gender, len(GENDER_VOCAB))\n",
    "\n",
    "    education = categorical_from_vocab_list(row[EDUCATION], EDUCATION_VOCAB)\n",
    "    education_oh = np_utils.to_categorical(gender, len(EDUCATION_VOCAB))\n",
    "\n",
    "        \n",
    "    marital_status = categorical_from_vocab_list(row[MARITAL_STATUS], MARITAL_STATUS_VOCAB)\n",
    "    marital_status_oh = np_utils.to_categorical(marital_status, len(MARITAL_STATUS_VOCAB))\n",
    "\n",
    "    \n",
    "    relationship = categorical_from_vocab_list(row[RELATIONSHIP], RELATIONSHIP_VOCAB)\n",
    "    relationship_oh = np_utils.to_categorical(relationship, len(RELATIONSHIP_VOCAB))\n",
    "\n",
    "    workclass = categorical_from_vocab_list(row[WORKCLASS], WORKCLASS_VOCAB)\n",
    "    workclass_oh = np_utils.to_categorical(workclass, len(WORKCLASS_VOCAB))\n",
    "\n",
    "\n",
    "    wide_input = np.concatenate([gender_oh, education_oh, marital_status_oh, relationship_oh, workclass_oh,\n",
    "                                 np_utils.to_categorical(hashbucket(row[OCCUPATION], 1000), 1000),\n",
    "                                 np_utils.to_categorical(hashbucket(row[NATIVE_COUNTRY], 1000), 1000),\n",
    "                                 np.array(get_boundaries(int(row[AGE]), AGE_BOUNDARIES)).reshape([1, 1]),\n",
    "                                 np_utils.to_categorical(hashbucket(row[EDUCATION] + row[OCCUPATION], 1000), 1000),\n",
    "                                 np_utils.to_categorical(hashbucket(str(row[AGE]) + row[EDUCATION] + row[OCCUPATION], 1000), 1000),\n",
    "                                 np_utils.to_categorical(hashbucket(row[NATIVE_COUNTRY] + row[OCCUPATION], 1000), 1000)], axis=1)\n",
    "\n",
    "    deep_column_indicator = np.zeros(33)\n",
    "    \n",
    "    deep_column_indicator[workclass] = 1  ## total 9 workclass\n",
    "    deep_column_indicator[education + 9] = 1 ## total 16 education\n",
    "    deep_column_indicator[gender + 25] = 1\n",
    "    deep_column_indicator[relationship + 27] = 1\n",
    "    \n",
    "    deep_column_embedding_1 = np.zeros(1)\n",
    "    deep_column_embedding_1[0] = hashbucket(row[NATIVE_COUNTRY], 1000) + 1 # label in bigdl is one-based\n",
    "    \n",
    "    deep_column_embedding_2 = np.zeros(1)\n",
    "    deep_column_embedding_2[0] = hashbucket(row[OCCUPATION], 1000) + 1\n",
    "    \n",
    "    deep_column_numeric = np.zeros(5)\n",
    "\n",
    "    deep_column_numeric[0] = row[AGE]\n",
    "    deep_column_numeric[1] = row[EDUCATION_NUM]\n",
    "    deep_column_numeric[2] = row[CAPITAL_GAIN]\n",
    "    deep_column_numeric[3] = row[CAPITAL_LOSS]\n",
    "    deep_column_numeric[4] = row[HOURS_PER_WEEK]\n",
    "    \n",
    "    label = get_label(row[LABEL])\n",
    "\n",
    "    wide_input = JTensor.from_ndarray(wide_input.squeeze())\n",
    "    deep_column_indicator = JTensor.from_ndarray(deep_column_indicator.reshape([33]))\n",
    "    deep_column_embedding_1 = JTensor.from_ndarray(deep_column_embedding_1.reshape([1]))\n",
    "    deep_column_embedding_2 = JTensor.from_ndarray(deep_column_embedding_2.reshape([1]))\n",
    "    deep_column_numeric = JTensor.from_ndarray(deep_column_numeric)\n",
    "\n",
    "   # return wide_input, deep_column_indicator, deep_column_embedding_1, deep_column_embedding_2, deep_column_numeric\n",
    "   # return Sample.from_jtensor([wide_input, deep_column_indicator, deep_column_embedding_1, deep_column_embedding_2, deep_column_numeric], label)\n",
    "    return Sample.from_jtensor([wide_input, deep_column_indicator, deep_column_embedding_1, deep_column_embedding_1], label)\n",
    "\n",
    "    \n",
    "#print(to_sample(train_records.first())[1].shape)\n",
    "train_data = train_records.map(lambda line: to_sample(line))\n",
    "test_data = test_records.map(lambda line: to_sample(line))\n",
    "train_data.first().features[0]\n",
    "\n",
    "train_data.cache()\n",
    "print \"Total train records: %s\" % train_data.count()\n",
    "test_data.cache()\n",
    "print \"Total test records: %s\" % test_data.count()\n",
    "print train_data.first().features[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cache the Training and Testing data RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the Wide&Deep model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:26:22.525600Z",
     "start_time": "2018-04-03T10:26:22.216945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createKerasInput\n",
      "creating: createKerasInput\n",
      "creating: createKerasInput\n",
      "creating: createKerasInput\n",
      "creating: createKerasReshape\n",
      "creating: createKerasReshape\n",
      "creating: createKerasEmbedding\n",
      "creating: createKerasReshape\n",
      "creating: createKerasReshape\n",
      "creating: createKerasEmbedding\n",
      "creating: createKerasInput\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-e0f23cc26ca2>:1: SyntaxWarning: import * only allowed at module level\n",
      "  def build_model(class_num = 2):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createKerasMerge\n",
      "creating: createKerasDense\n",
      "creating: createKerasDense\n",
      "creating: createKerasMerge\n",
      "creating: createKerasDense\n",
      "creating: createKerasActivation\n",
      "creating: createKerasModel\n",
      "Wide&Deep model:\n",
      " Model[e881fe75]\n"
     ]
    }
   ],
   "source": [
    "def build_model(class_num = 2):\n",
    "    from bigdl.nn.keras.topology import Model, Sequential\n",
    "    from bigdl.nn.keras.layer import *\n",
    "    wide_in = Input(shape=[5041])  # 5006?\n",
    "    deep_indicator_input = Input(shape=[33])\n",
    "    deep_embedding_1_input = Input(shape=[1])\n",
    "    deep_embedding_2_input = Input(shape=[1])\n",
    "\n",
    "    \n",
    "    e1 = Reshape([1], input_shape=[1])(deep_embedding_1_input)\n",
    "    deep_embedding_1 = Reshape([8])(Embedding(1000, 8, input_shape=[1])(e1))\n",
    "\n",
    "    e2 = Reshape([1], input_shape=[1])(deep_embedding_2_input)\n",
    "    deep_embedding_2 = Reshape([8])(Embedding(1000, 8, input_shape=[1])(e2))\n",
    "    \n",
    "    deep_numerics_input = Input(shape=[5])\n",
    "    deep_out = merge(inputs=[deep_indicator_input, deep_embedding_1, deep_embedding_2], mode=\"concat\", concat_axis=1)\n",
    "\n",
    "    deep_fc_1 = Dense(100, activation = \"ReLU\").set_name(\"fc_1\")(deep_out)\n",
    "    deep_fc_2 = Dense(50, activation = \"ReLU\").set_name(\"fc_2\")(deep_fc_1)\n",
    "    w_n_d_out = merge(inputs=[wide_in, deep_fc_2], mode=\"concat\", concat_axis=1)\n",
    "     \n",
    "    linear_out = Dense(class_num).set_name(\"fc_3\")(w_n_d_out)\n",
    "    final_out = Activation(\"SoftMax\")(linear_out)\n",
    "    deepModel = Model([wide_in, deep_indicator_input, deep_embedding_1_input, deep_embedding_2_input], final_out)\n",
    "    return deepModel\n",
    "\n",
    "\n",
    "wide_n_deep=build_model()\n",
    "print \"Wide&Deep model:\\n %s\" % wide_n_deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create optimizer and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-03T10:30:21.076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createAdam\n",
      "creating: createClassNLLCriterion\n",
      "creating: createTop1Accuracy\n",
      "creating: createClassNLLCriterion\n",
      "creating: createAdam\n",
      "creating: createMaxEpoch\n",
      "creating: createDistriOptimizer\n",
      "creating: createSeveralIteration\n",
      "creating: createTop1Accuracy\n",
      "creating: createClassNLLCriterion\n",
      "creating: createLoss\n",
      "creating: createTrainSummary\n",
      "creating: createValidationSummary\n",
      "saving logs to /tmp/bigdl_summaries/wide_n_deep-20180403-183021\n"
     ]
    }
   ],
   "source": [
    "# Create an Optimizer\n",
    "\n",
    "wide_n_deep.compile(optimizer=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n",
    "                    loss=ClassNLLCriterion(logProbAsInput=False),\n",
    "                    metrics=[Top1Accuracy()])\n",
    "# wide_n_deep.fit(train_data, batch_size=100, nb_epoch=7, validation_data=test_data) # epoch is 7, batch_size=100\n",
    "\n",
    "batch_size = 100\n",
    "optimizer = Optimizer(\n",
    "    model=wide_n_deep,\n",
    "    training_rdd=train_data,\n",
    "    criterion=ClassNLLCriterion(logProbAsInput=False),\n",
    "    optim_method=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n",
    "    end_trigger=MaxEpoch(40),\n",
    "\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Set the validation logic\n",
    "optimizer.set_validation(\n",
    "    batch_size=batch_size,\n",
    "    val_rdd=test_data,\n",
    "    trigger=SeveralIteration(200),\n",
    "    val_method=[Top1Accuracy(), Loss()]\n",
    ")\n",
    "log_dir='/tmp/bigdl_summaries/'\n",
    "app_name='wide_n_deep-'+dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_summary = TrainSummary(log_dir=log_dir,\n",
    "                                     app_name=app_name)\n",
    "val_summary = ValidationSummary(log_dir=log_dir,\n",
    "                                        app_name=app_name)\n",
    "optimizer.set_train_summary(train_summary)\n",
    "optimizer.set_val_summary(val_summary)\n",
    "print \"saving logs to %s\" % (log_dir + app_name)\n",
    "optimizer.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network. Wait some time till it finished.. Voila! You've got a trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the trained model\n",
    "Will return a Top1 Accuracy about 84%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:29:20.027987Z",
     "start_time": "2018-04-03T10:29:19.762020Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes at least 3 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cfeeb0c94273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'evaluate_result=Model(wide_n_deep).evaluate(test_data)\\nprint \"Top1 accuracy: %s\" % evaluate_result[0].result'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/lizhichao/anaconda/envs/bigdl04py27/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/lizhichao/anaconda/envs/bigdl04py27/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lizhichao/anaconda/envs/bigdl04py27/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes at least 3 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate_result=wide_n_deep.evaluate(test_data) # !!NOTE there's bug here that you need to invoke \"compile\" before calling this method.\n",
    "print \"Top1 accuracy: %s\" % evaluate_result[0].result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Draw the convergence curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-03T10:31:52.094Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = np.array(train_summary.read_scalar(\"Loss\"))\n",
    "top1 = np.array(val_summary.read_scalar(\"Top1Accuracy\"))\n",
    "\n",
    "plt.figure(figsize = (12,12))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(loss[:,0],loss[:,1],label='loss')\n",
    "plt.xlim(0,loss.shape[0]+10)\n",
    "plt.grid(True)\n",
    "plt.title(\"loss\")\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(top1[:,0],top1[:,1],label='top1')\n",
    "plt.xlim(0,loss.shape[0]+10)\n",
    "plt.title(\"top1 accuracy\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
