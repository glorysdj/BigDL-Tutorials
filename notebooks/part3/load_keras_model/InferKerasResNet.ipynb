{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T13:35:56.282828Z",
     "start_time": "2018-04-03T13:35:56.278588Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: export SPARK_DRIVER_MEMORY=1g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import imagenet_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For resnet, we only support NCHW and Keras 1.2.2 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.set_image_dim_ordering(\"th\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create ResNet50 using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lizhichao/anaconda3/envs/keras2/lib/python3.5/site-packages/keras/applications/resnet50.py:231: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image dimension ordering convention (`image_dim_ordering=\"th\"`). For best performance, set `image_dim_ordering=\"tf\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    }
   ],
   "source": [
    "keras_model = ResNet50(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Init BigDL and spark environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding /home/lizhichao/anaconda3/envs/keras2/lib/python3.5/site-packages/bigdl/share/lib/bigdl-0.6.0-jar-with-dependencies.jar to BIGDL_JARS\n",
      "Prepending /home/lizhichao/anaconda3/envs/keras2/lib/python3.5/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\n"
     ]
    }
   ],
   "source": [
    "from bigdl.keras.backend import *\n",
    "from bigdl.transform.vision.image import *\n",
    "\n",
    "redire_spark_logs()\n",
    "show_bigdl_info_logs()\n",
    "init_engine()\n",
    "sparkConf = create_spark_conf().setAppName(\"test model\")\n",
    "sc = get_spark_context(sparkConf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load a Keras definition and weights to BigDL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createInput\n",
      "creating: createSequential\n",
      "creating: createPadding\n",
      "creating: createPadding\n",
      "creating: createPadding\n",
      "creating: createPadding\n",
      "creating: createSpatialConvolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lizhichao/anaconda3/envs/keras2/lib/python3.5/site-packages/bigdl/keras/converter.py:791: UserWarning: Cannot find dim_ordering from json definition. Using the default instead.\n",
      "  warnings.warn(\"Cannot find dim_ordering from json definition. Using the default instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createCAddTable\n",
      "creating: createReLU\n",
      "creating: createSpatialAveragePooling\n",
      "creating: createReshape\n",
      "creating: createLinear\n",
      "creating: createXavier\n",
      "creating: createZeros\n",
      "creating: createSoftMax\n",
      "creating: createSequential\n",
      "creating: createModel\n"
     ]
    }
   ],
   "source": [
    "bmodel = DefinitionLoader.from_kmodel(keras_model)\n",
    "WeightLoader.load_weights_from_kmodel(bmodel, keras_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load data into ImageFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_frame = ImageFrame.read(\"image-net\", sc=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define prepocess transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createBytesToMat\n",
      "creating: createResize\n",
      "creating: createCenterCrop\n",
      "creating: createChannelNormalize\n",
      "creating: createMatToTensor\n",
      "creating: createImageFrameToSample\n",
      "creating: createPipeline\n"
     ]
    }
   ],
   "source": [
    "transformer = Pipeline([BytesToMat(), Resize(256, 256),\n",
    "                        CenterCrop(224, 224),\n",
    "                        ChannelNormalize(123.68, 103.939, 116.779),\n",
    "                        MatToTensor(), ImageFrameToSample()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:14:49.401336Z",
     "start_time": "2018-04-03T10:14:24.584480Z"
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o27.modelPredictImage.\n: java.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:3236)\n\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)\n\tat org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:337)\n\tat org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:330)\n\tat org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:156)\n\tat org.apache.spark.SparkContext.clean(SparkContext.scala:2294)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1.apply(RDD.scala:794)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1.apply(RDD.scala:793)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.mapPartitions(RDD.scala:793)\n\tat com.intel.analytics.bigdl.optim.Predictor.predictImage(Predictor.scala:198)\n\tat com.intel.analytics.bigdl.nn.abstractnn.AbstractModule.predictImage(AbstractModule.scala:666)\n\tat com.intel.analytics.bigdl.python.api.PythonBigDL.modelPredictImage(PythonBigDL.scala:1955)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b118ead86295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.5/site-packages/bigdl/nn/layer.py\u001b[0m in \u001b[0;36mpredict_image\u001b[0;34m(self, image_frame, output_layer, share_buffer, batch_per_partition, predict_key)\u001b[0m\n\u001b[1;32m    466\u001b[0m                              \u001b[0mshare_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                              \u001b[0mbatch_per_partition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                              predict_key)\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mImageFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.5/site-packages/bigdl/util/common.py\u001b[0m in \u001b[0;36mcallBigDlFunc\u001b[0;34m(bigdl_type, name, *args)\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"does not exist\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.5/site-packages/bigdl/util/common.py\u001b[0m in \u001b[0;36mcallBigDlFunc\u001b[0;34m(bigdl_type, name, *args)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjinvoker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallJavaFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.5/site-packages/bigdl/util/common.py\u001b[0m in \u001b[0;36mcallJavaFunc\u001b[0;34m(func, *args)\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0mgateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.5/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.5/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o27.modelPredictImage.\n: java.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:3236)\n\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)\n\tat org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:337)\n\tat org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:330)\n\tat org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:156)\n\tat org.apache.spark.SparkContext.clean(SparkContext.scala:2294)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1.apply(RDD.scala:794)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1.apply(RDD.scala:793)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.mapPartitions(RDD.scala:793)\n\tat com.intel.analytics.bigdl.optim.Predictor.predictImage(Predictor.scala:198)\n\tat com.intel.analytics.bigdl.nn.abstractnn.AbstractModule.predictImage(AbstractModule.scala:666)\n\tat com.intel.analytics.bigdl.python.api.PythonBigDL.modelPredictImage(PythonBigDL.scala:1955)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n"
     ]
    }
   ],
   "source": [
    "preds_frame = bmodel.predict_image(image_frame.transform(transformer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show result of the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:14:53.330368Z",
     "start_time": "2018-04-03T10:14:49.404042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for hdfs://ng3afac14-master-instance-0oof254w.novalocal:8020/user/root/image-net/158516268_796c3e047d.jpg\n",
      "    1. sorrel: 96.77%\n",
      "    2. ox: 0.72%\n",
      "    3. llama: 0.52%\n",
      "    4. gazelle: 0.42%\n",
      "    5. basenji: 0.23%\n"
     ]
    }
   ],
   "source": [
    "preds = preds_frame.get_predict().take(1)\n",
    "\n",
    "for pre in preds:\n",
    "    path, pre_score = pre\n",
    "    P = imagenet_utils.decode_predictions(np.expand_dims(pre_score, axis=0))\n",
    "    print(\"Prediction for {}\".format(path))\n",
    "    # Display the top-5 prediction\n",
    "    for (i, (imagenetID, label, prob)) in enumerate(P[0]):\n",
    "        print(\"    {}. {}: {:.2f}%\".format(i + 1, label, prob * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* While the origin image is\n",
    "![scalars](image-net/158516268_796c3e047d.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (keras2)",
   "language": "python",
   "name": "keras2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
